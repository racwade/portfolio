{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as d\n",
    "from numpy import linalg as la\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgarr = []\n",
    "img = cv2.imread('yosemite1.jpg')\n",
    "imgarr.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "img = cv2.imread('yosemite4.jpg')\n",
    "imgarr.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "img = cv2.imread('yosemite3.jpg')\n",
    "imgarr.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "img = cv2.imread('yosemite2.jpg')\n",
    "imgarr.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def img_match(image1, image2):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    src1 = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "    src1 = np.uint8(src1)\n",
    "    src2 = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "    src2 = np.uint8(src2)\n",
    "    kp1 = sift.detect(src1, None)\n",
    "    kp2 = sift.detect(src2, None)\n",
    "    kp1, des1 = sift.compute(src1, kp1)\n",
    "    kp2, des2 = sift.compute(src2, kp2)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1,des2, k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.90*n.distance or n.distance < 0.90*m.distance:\n",
    "            good.append((m.queryIdx, m.trainIdx))\n",
    "            \n",
    "    if(len(kp1) < len(kp2)):\n",
    "        num_points = len(kp1)\n",
    "    else:\n",
    "        num_points = len(kp2)\n",
    "    trans = np.zeros((3,3))\n",
    "    if(len(good) >= 4):\n",
    "        #print(good[0][0])\n",
    "        img1_pts = []\n",
    "        img2_pts = []\n",
    "        for point in range(0,len(good)):\n",
    "            img1_pts.append(kp1[good[point][0]].pt)\n",
    "            img2_pts.append(kp2[good[point][1]].pt)\n",
    "        #img1_pt1 = kp1[good[0][0].trainIdx].pt\n",
    "        #img1_pt2 = kp1[good[1][0].trainIdx].pt\n",
    "        #img1_pt3 = kp1[good[2][0].trainIdx].pt\n",
    "        #img2_pt1 = kp2[good[0][1].trainIdx].pt\n",
    "        #img2_pt2 = kp2[good[1][1].trainIdx].pt\n",
    "        #img3_pt3 = kp2[good[2][1].trainIdx].pt\n",
    "        #img1_arr = np.float32([img1_pt1,img2_pt2,img3_pt3])\n",
    "        #img2_arr = np.float32([img2_pt1, img2_pt2, img3_pt3])\n",
    "        #print(img1_arr)\n",
    "        #trans = cv2.getAffineTransform(img1_arr,img2_arr)\n",
    "        trans,status = cv2.findHomography(np.float32(img1_pts),np.float32(img2_pts), cv2.RANSAC, 4.0)\n",
    "    return (len(good)/num_points,trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('Match score is', img_match(imgarr[1], imgarr[2]))\n",
    "weights = np.zeros((len(imgarr), len(imgarr)))\n",
    "for i in range(0,len(imgarr)):\n",
    "    for j in range(0,len(imgarr)):\n",
    "        if(i == j):\n",
    "            weights[i][j] = -1\n",
    "            continue\n",
    "        value,func = img_match(imgarr[i], imgarr[j])\n",
    "        weights[i][j] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 3840, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "height, width, channels = imgarr[0].shape\n",
    "#(height*(len(imgarr)+2)\n",
    "bigimage = np.zeros((height,width*(len(imgarr)+2),channels), np.uint8)\n",
    "print(bigimage.shape)\n",
    "print(imgarr[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imgmerge(img_base,img_add,trans):\n",
    "    warpheight = img_base.shape[0]\n",
    "    warpwidth = img_base.shape[1]+img_add.shape[1]\n",
    "    warpimg = np.zeros((warpheight,warpwidth,channels), np.uint8)\n",
    "    warpimg[0:img_add.shape[0],0:img_add.shape[1]] = img_add\n",
    "    added_width = trans[len(transformations)-1][0][2]\n",
    "    for k in range(0,len(transformations)):\n",
    "        warpimg = cv2.warpPerspective(warpimg,transformations[k], (warpwidth,warpheight))\n",
    "    #warpimg = cv2.warpPerspective(img_add, trans[0], (warpwidth,warpheight))\n",
    "    warpimg[0:img_base.shape[0], 0:img_base.shape[1]] = img_base\n",
    "    result = warpimg[:,0:(int(img_base.shape[1]+added_width))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match for image 0 is 3\n",
      "Best match for image 3 is 2\n",
      "Best match for image 2 is 1\n"
     ]
    }
   ],
   "source": [
    "transformations = []\n",
    "done_images = []\n",
    "result = imgarr[0].copy()\n",
    "i = 0 #pointer to image of interest\n",
    "done_images.append(i)\n",
    "#for i in range(0,len(imgarr)):\n",
    "#for i in range(0,1):\n",
    "while(len(done_images) < len(imgarr)):\n",
    "    bestmatch = -1\n",
    "    bestmatch_val = 0\n",
    "    for j in range(0,len(imgarr)):\n",
    "        if(j in done_images):\n",
    "            continue\n",
    "        weight = weights[j][i]\n",
    "        #if(weight == -1):\n",
    "        #    weight = weights[i][j]\n",
    "        if weight > bestmatch_val:\n",
    "            bestmatch = j\n",
    "            bestmatch_val = weight\n",
    "    print(\"Best match for image \" + str(i) + \" is \" + str(bestmatch))\n",
    "    if(bestmatch != -1):\n",
    "        value,func = img_match(imgarr[bestmatch], imgarr[i])\n",
    "        transformations.append(func)\n",
    "        #print(func)\n",
    "        result = imgmerge(result,imgarr[bestmatch],transformations)\n",
    "    done_images.append(i)\n",
    "    i = bestmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imshow('test',result)\n",
    "cv2.imwrite('out.jpg',cv2.cvtColor(result, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
